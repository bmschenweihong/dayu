# 批量数据迁移概述<a name="dayu_01_0013"></a>

DAYU批量数据迁移（Cloud Data Migration）提供同构/异构数据源之间批量数据迁移服务，帮助您实现数据自由流动。支持自建和云上的文件系统，关系数据库，数据仓库，NoSQL，大数据云服务，对象存储等数据源。

## 批量数据集成简介<a name="zh-cn_topic_0108275398_section69302054123512"></a>

批量数据迁移基于分布式计算框架，利用并行化处理技术，支持用户稳定高效地对海量数据进行移动，实现不停服数据迁移，快速构建所需的数据架构。

**图 1**  批量数据迁移定位<a name="zh-cn_topic_0108275398_fig1311414214272"></a>  
![](figures/批量数据迁移定位.png "批量数据迁移定位")

## 产品功能<a name="zh-cn_topic_0108275398_section8948312133415"></a>

-   **表/文件/整库迁移**

    支持批量迁移表或者文件，还支持同构/异构数据库之间整库迁移，一个作业即可迁移几百张表。

-   **增量数据迁移**

    支持文件增量迁移、关系型数据库增量迁移、HBase/CloudTable增量迁移，以及使用Where条件配合时间变量函数实现增量数据迁移。

-   **事务模式迁移**

    支持当批量数据迁移作业执行失败时，将数据回滚到作业开始之前的状态，自动清理目的表中的数据。

-   **字段转换**

    支持去隐私、字符串操作、日期操作等常用字段的数据转换功能。

-   **文件加密**

    在迁移文件到文件系统时，CDM支持对写入云端的文件进行加密。

-   **MD5校验一致性**

    支持使用MD5校验，检查端到端文件的一致性，并输出校验结果。

-   **脏数据归档**

    支持将迁移过程中处理失败的、被清洗过滤掉的、不符合字段转换或者不符合清洗规则的数据单独归档到脏数据日志中，便于用户查看。并支持设置脏数据比例阈值，来决定任务是否成功。


## **批量数据迁移系统级限制和约束**<a name="zh-cn_topic_0108275404_section41741324807"></a>

1.  集群创建好以后不支持修改规格，如果需要使用更高规格的，需要重新创建一个集群。
2.  批量数据迁移暂不支持控制迁移数据的速度，请避免在业务高峰期执行迁移数据的任务。
3.  批量数据迁移所有集群实例规格目前的网卡带宽均为1Gbps，单个实例一天传输数据量的理论极限值为10TB，对传输速度有要求的情况下可以使用多个批量数据迁移实例实现。

    上述数据量为理论极限值，实际传输数据量受数据源类型、源和目的数据源读写性能、带宽等多方面因素制约，实测最大可达到约8TB每天（大文件迁移到OBS场景）。推荐用户在正式迁移前先用小数据量实测进行速度摸底。

4.  批量数据迁移迁移文件或对象时支持文件级增量迁移（通过配置跳过重复文件实现），但不支持断点续传。

    例如要迁移3个文件，第2个文件迁移到一半时由于网络原因失败，再次启动迁移任务时，会跳过第1个文件，从第2个文件开始重新传，但不能从第2个文件失败的位置重新传。

5.  文件迁移时，单个任务支持千万数量的文件，如果待迁移目录下文件过多，建议拆分到不同目录并创建多个任务。
6.  批量数据迁移单个实例同一时刻执行的任务数按大、中、小三种规格，分别为30、20、10。等待执行（Pending状态）的作业队列数量分别为10000、5000、2000。

    这里的一个作业在数据库迁移场景下等价于迁移一张表，在文件迁移场景下一个作业可以迁移多个文件。

7.  用户在批量数据迁移上配置的连接和作业支持导出到本地保存，考虑到密码的安全性，批量数据迁移不会将对应数据源的连接密码导出。因此在将作业配置重新导入到批量数据迁移前，需要手工编辑导出的JSON文件补充密码。
8.  不支持集群自动升级到新版本，需要用户通过作业的导出和导入功能，实现升级到新版本。
9.  批量数据迁移系统不会自动备份用户的作业配置，需要用户通过作业的导出功能进行备份。
10. 如果配置了VPC对等连接，可能会出现对端VPC子网与批量数据迁移管理网重叠，从而无法访问对端VPC中数据源的情况。推荐使用公网做跨VPC数据迁移，或联系管理员在批量数据迁移后台为VPC对等连接添加特定路由。

